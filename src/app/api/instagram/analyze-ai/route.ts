
import { BrutalUserPromptParams, RawAnalysisResult } from "@/app/instagram/types";
import genAI from "@/lib/gemini";
import { BRUTAL_ANALYST_SYSTEM_PROMPT } from "@/lib/prompts/brutal-analyst";
import { INSTAGRAM_ANALYSIS_SCHEMA } from "@/lib/schemas/analysis";
import { supabase } from "@/lib/supabase";
import { NextResponse } from "next/server";

// Re-using local prompt builder (or could export it)
// Ideally this should be shared, but copying for safety and speed as prompted by refactor plan.

function buildBrutalUserPrompt(params: BrutalUserPromptParams): string {
  const { username, fullName, biography, followers, metrics, trendMetrics, postsData } = params;
  
  // ê²Œì‹œê¸€ í…ìŠ¤íŠ¸ êµ¬ì„±
  const postsText = postsData.map((post, i) => {
    const commentsText = post.comments
      .slice(0, 20)
      .map((c, j) => `${j + 1}. @${c.username}: "${c.text}"${c.likes ? ` (${c.likes} ì¢‹ì•„ìš”)` : ''}`)
      .join('\n');
    
    return `
ê²Œì‹œê¸€ #${i + 1}:
ìº¡ì…˜: ${post.caption || '(ì—†ìŒ)'}
í•´ì‹œíƒœê·¸: ${post.hashtags?.join(', ') || '(ì—†ìŒ)'}
ëŒ“ê¸€ ìˆ˜: ${post.comments.length}ê°œ

ëŒ“ê¸€ ìƒ˜í”Œ:
${commentsText || '(ëŒ“ê¸€ ì—†ìŒ)'}`;
  }).join('\n\n---\n');

  // íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ (30ê°œ ê²Œì‹œë¬¼ ê¸°ë°˜)
  const trendText = trendMetrics ? `
**íŠ¸ë Œë“œ ë¶„ì„ (30ê°œ ê²Œì‹œë¬¼ ê¸°ë°˜):**
- ER ì¶”ì„¸: ${trendMetrics.erTrend === 'rising' ? 'ðŸ“ˆ ìƒìŠ¹' : trendMetrics.erTrend === 'declining' ? 'ðŸ“‰ í•˜ë½' : 'âž¡ï¸ ìœ ì§€'} (${trendMetrics.erChangePercent > 0 ? '+' : ''}${trendMetrics.erChangePercent}%)
- êµ¬ê°„ë³„ ER:
- êµ¬ê°„ë³„ ER:
  - ìµœê·¼ 10ê°œ: ${(trendMetrics.periodComparison.recent.er || 0).toFixed(2)}% (ì¢‹ì•„ìš” í‰ê·  ${trendMetrics.periodComparison.recent.avgLikes}ê°œ)
  - ì¤‘ê°„ 10ê°œ: ${(trendMetrics.periodComparison.middle.er || 0).toFixed(2)}% (ì¢‹ì•„ìš” í‰ê·  ${trendMetrics.periodComparison.middle.avgLikes}ê°œ)
  - ì´ì „ 10ê°œ: ${(trendMetrics.periodComparison.oldest.er || 0).toFixed(2)}% (ì¢‹ì•„ìš” í‰ê·  ${trendMetrics.periodComparison.oldest.avgLikes}ê°œ)
- í‰ê·  ì—…ë¡œë“œ ì£¼ê¸°: ${trendMetrics.avgUploadFrequency}ì¼
` : '';

  // ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ (Data Only)
  return `## íˆ¬ìžì‹¬ì‚¬ ëŒ€ìƒ ì¸í”Œë£¨ì–¸ì„œ

**ê¸°ë³¸ ì •ë³´:**
- Username: @${username}
- ì´ë¦„: ${fullName || 'ë¯¸ê³µê°œ'}
- ë°”ì´ì˜¤: ${biography || 'ì—†ìŒ'}
- íŒ”ë¡œì›Œ: ${followers.toLocaleString()}ëª…
- í‹°ì–´: ${metrics.tier}

**ì •ëŸ‰ ë¶„ì„ (ì‹œìŠ¤í…œ ê³„ì‚°):**
- Engagement Rate: ${(metrics.engagementRate || 0).toFixed(2)}%
- ER ë“±ê¸‰: ${metrics.erGrade || 'ë¯¸ì‚°ì •'}
- ì‹ ë¢°ë„ ì ìˆ˜: ${metrics.authenticityScore}/100
- ê°€ì§œ ì˜ì‹¬: ${metrics.isFake ? 'ì˜ˆ âš ï¸' : 'ì•„ë‹ˆì˜¤'}
- í™œë™ ìƒíƒœ: ${metrics.isActive ? 'í™œì„±' : 'ë¹„í™œì„±'}
- ì—…ë¡œë“œ ì£¼ê¸°: ${metrics.avgUploadCycle !== null ? metrics.avgUploadCycle + 'ì¼' : 'ì¸¡ì • ë¶ˆê°€'}
- ì‹œìž¥ ê¸°ì¤€: ${metrics.marketSuitable ? 'ì¶©ì¡± âœ“' : 'ë¯¸ë‹¬ âœ—'}
${trendText}
**ìº íŽ˜ì¸ ì í•©ë„ (ì‹œìŠ¤í…œ ê³„ì‚°):**
- í˜‘ì°¬: ${metrics.campaignSuitability.sponsorship.grade}ê¸‰ (${metrics.campaignSuitability.sponsorship.score}ì )
- ìœ ë£Œ ê´‘ê³ : ${metrics.campaignSuitability.paidAd.grade}ê¸‰ (${metrics.campaignSuitability.paidAd.score}ì )
- ê³µë™êµ¬ë§¤: ${metrics.campaignSuitability.coPurchase.grade}ê¸‰ (${metrics.campaignSuitability.coPurchase.score}ì )

**ê²Œì‹œê¸€ ë°ì´í„° (ìµœê·¼ 10ê°œ):**
${postsText}`;
}

export async function POST(req: Request) {
  try {
    const body = await req.json();
    const { rawData, promptType = 'INSTA' } = body; // rawData is array of RawAnalysisResult

    if (!rawData || !Array.isArray(rawData)) {
      return NextResponse.json({ error: "Invalid raw data" }, { status: 400 });
    }

    // Fetch analysis limit and system prompt from DB
    let analysisLimit = 10;
    let systemPrompt = BRUTAL_ANALYST_SYSTEM_PROMPT; // Default fallback
    
    // Validate promptType
    const validPromptType = (promptType === 'INSTA' || promptType === 'INSTA_TARGET') ? promptType : 'INSTA';

    try {
      // Parallel fetch for Settings and Prompt
      const [settingRes, promptRes] = await Promise.all([
        supabase.from('settings').select('value').eq('key', 'insta_analysis_limit').single(),
        supabase.from('prompts').select('content').eq('prompt_type', validPromptType).eq('is_default', true).single()
      ]);
      
      if (settingRes.data?.value) {
        analysisLimit = parseInt(settingRes.data.value, 10) || 10;
      }
      
      if (promptRes.data?.content) {
        systemPrompt = promptRes.data.content;
      }
    } catch (e) {
      console.warn("Failed to fetch settings/prompt from DB, using defaults", e);
    }

    const analysisSchema = INSTAGRAM_ANALYSIS_SCHEMA;

    const model = genAI.getGenerativeModel({
      model: "gemini-2.0-flash",
      generationConfig: { 
        responseMimeType: "application/json",
        responseSchema: analysisSchema as any,
        temperature: 0.3
      }
    });

    const analyzedResults = await Promise.all(
      rawData.map(async (raw: RawAnalysisResult) => {
        if (!raw.success || !raw.verifiedProfile || !raw.metrics) {
            return {
                username: raw.username,
                success: false,
                error: "Missing required raw data for verification"
            };
        }

        const user = raw.verifiedProfile;
        const posts = raw.recent_posts || [];

        // Prepare posts data (slice for AI context)
        const postsData = posts
          .slice(0, analysisLimit)
          .map((post: any) => {
             // Adapt field names if necessary. Assuming fetch-raw normalized them.
             // fetch-raw puts: likes, comments (number), timestamp.
             // But prompt needs comments text.
             // Oh, fetch-raw might have stripped comments text if I wasn't careful.
             // Checking fetch-raw code: I passed fetchedPosts = postItems directly.
             // Apify postItems often contain `latestComments` or similar.
             // I need to ensure fetch-raw preserves comment text access.
             
             // Re-checking fetch-raw... I mapped `fetchedPosts = postItems.map...`
             // and returned `recent_posts: fetchedPosts`.
             // I verified `latest_comments` is crucial. 
             // In fetch-raw, I did `...p`. So raw Apify fields should be there.
             // Apify fields: `latestComments` usually.
             
            const fanComments = (post.latestComments || post.latest_comments || [])
              .filter((c: any) => c.ownerUsername !== user.username)
              .slice(0, 20);

            return {
              caption: post.caption || '',
              hashtags: post.hashtags || [],
              comments: fanComments.map((c: any) => ({
                username: c.ownerUsername || 'unknown',
                text: c.text || '',
                likes: c.likesCount || c.likes || 0
              }))
            };
          });

        const userPrompt = buildBrutalUserPrompt({
          username: user.username,
          fullName: user.fullName || '',
          biography: user.biography || '',
          followers: user.followers,
          metrics: { 
              ...raw.metrics, 
              erGrade: raw.metrics.erGrade || 'ë¯¸ì‚°ì •',
              // Fix potential type mismatch for avgUploadCycle (number | null -> number w/ fallback handled in string)
           } as any, 
          trendMetrics: raw.trendMetrics || undefined,
          postsData: postsData
        });

        // Prepare images
        // We need to fetch images again here? Or did we pass base64? Passing base64 is heavy.
        // Better to fetch here by URL.
        const imageParts = [];
        for (const post of posts.slice(0, analysisLimit)) {
             // Use displayUrl or imageUrl
             const imgUrl = post.displayUrl || post.imageUrl || post.display_url;
             if (imgUrl) {
                try {
                  const imageResp = await fetch(imgUrl, {
                    headers: {
                      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                      "Referer": "https://www.instagram.com/"
                    }
                  });

                  if (imageResp.ok) {
                    const imageBuffer = await imageResp.arrayBuffer();
                    imageParts.push({
                      inlineData: {
                        data: Buffer.from(imageBuffer).toString("base64"),
                        mimeType: "image/jpeg"
                      }
                    });
                  }
                } catch (e) {
                  console.error(`Failed to fetch image for ${user.username} in AI stage`, e);
                }
             }
        }

        try {
          const fullPrompt = `${systemPrompt}\n\n---\n\n${userPrompt}`;
          const result = await model.generateContent([fullPrompt, ...imageParts]);
          const response = await result.response;
          const text = response.text();

          let cleanedText = text
            .replace(/^```json\s*/, '')
            .replace(/^```\s*/, '')
            .replace(/\s*```$/, '');
          
          let analysis = JSON.parse(cleanedText);
          
          // Re-enforce Source of Truth logic just in case AI overwrites basicStats
          if (!analysis.basicStats) analysis.basicStats = {};
          analysis.basicStats.username = user.username;
          analysis.basicStats.followers = user.followers;
          analysis.basicStats.profilePicUrl = user.profilePicUrl || null;

          return {
            username: user.username,
            analysis, // The qualitative analysis
            verifiedProfile: user, // Pass it back for consistency context
            trendMetrics: raw.trendMetrics,
            success: true
          };

        } catch (error: any) {
          console.error(`AI Analysis failed for ${user.username}`, error);
          return {
            username: user.username,
            success: false,
            error: error.message
          };
        }
      })
    );

    return NextResponse.json({ results: analyzedResults });

  } catch (error: any) {
    console.error("AI Analysis Route Error:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
